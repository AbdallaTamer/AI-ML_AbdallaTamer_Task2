{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Dependencies"
      ],
      "metadata": {
        "id": "8W-XxhFQed7R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install selenium"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufugSx1_dusb",
        "outputId": "76e60a19-88d3-40fc-a7b3-b4ad0a4f4687"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting selenium\n",
            "  Downloading selenium-4.34.2-py3-none-any.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: urllib3~=2.5.0 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]~=2.5.0->selenium) (2.5.0)\n",
            "Collecting trio~=0.30.0 (from selenium)\n",
            "  Downloading trio-0.30.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting trio-websocket~=0.12.2 (from selenium)\n",
            "  Downloading trio_websocket-0.12.2-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: certifi>=2025.6.15 in /usr/local/lib/python3.11/dist-packages (from selenium) (2025.7.14)\n",
            "Requirement already satisfied: typing_extensions~=4.14.0 in /usr/local/lib/python3.11/dist-packages (from selenium) (4.14.1)\n",
            "Requirement already satisfied: websocket-client~=1.8.0 in /usr/local/lib/python3.11/dist-packages (from selenium) (1.8.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (25.3.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (3.10)\n",
            "Collecting outcome (from trio~=0.30.0->selenium)\n",
            "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (1.3.1)\n",
            "Collecting wsproto>=0.14 (from trio-websocket~=0.12.2->selenium)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]~=2.5.0->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from wsproto>=0.14->trio-websocket~=0.12.2->selenium) (0.16.0)\n",
            "Downloading selenium-4.34.2-py3-none-any.whl (9.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m79.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio-0.30.0-py3-none-any.whl (499 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m499.2/499.2 kB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio_websocket-0.12.2-py3-none-any.whl (21 kB)\n",
            "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: wsproto, outcome, trio, trio-websocket, selenium\n",
            "Successfully installed outcome-1.3.0.post0 selenium-4.34.2 trio-0.30.0 trio-websocket-0.12.2 wsproto-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup ChromeDriver"
      ],
      "metadata": {
        "id": "Q-sl8Eblel32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options"
      ],
      "metadata": {
        "id": "r5pu_ktdesBu"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "options = Options()\n",
        "options.add_argument(\"--headless\")  #run in the background without opening a browser window\n",
        "options.add_argument(\"--disable-gpu\")\n",
        "options.add_argument(\"--window-size=1920,1080\")\n",
        "options.add_argument(\"--no-sandbox\")  #for Linux environments like Colab\n",
        "options.add_argument(\n",
        "    \"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) Chrome/115.0 Safari/537.36\"\n",
        ")  #mimic real browser user-agent to reduce bot detection\n",
        "\n",
        "#launch Chrome with the defined options\n",
        "driver = webdriver.Chrome(options=options)"
      ],
      "metadata": {
        "id": "2zMhvlFYevZO"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# URL and Product Storage"
      ],
      "metadata": {
        "id": "W2MREhxhfTvB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_URL = \"https://www.jumia.com.eg/laptops/?page={page}\"\n",
        "#list to store all scraped products\n",
        "products = []"
      ],
      "metadata": {
        "id": "_6xo6SlNfGEy"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract Product Data"
      ],
      "metadata": {
        "id": "rezvvIeMfZd0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "    Extracts structured product info from a single product card on the page.\n",
        "    Each 'card' is an HTML <article> element."
      ],
      "metadata": {
        "id": "EMLXRaM3fmbQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup"
      ],
      "metadata": {
        "id": "hPgH9NYpffBb"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_data(card):\n",
        "    try:\n",
        "        title = card.find('h3').text.strip()\n",
        "    except:\n",
        "        title = None\n",
        "\n",
        "    try:\n",
        "        price = card.find('div', class_='prc').text.strip()\n",
        "    except:\n",
        "        price = None\n",
        "\n",
        "    try:\n",
        "        rating_tag = card.find('div', class_='stars')\n",
        "        #extract rating percentage\n",
        "        rating = rating_tag.get('style').split(':')[-1] if rating_tag else None\n",
        "    except:\n",
        "        rating = None\n",
        "\n",
        "    try:\n",
        "        #number of reviews as visible on product card\n",
        "        reviews = card.find('div', class_='rev').text.strip()\n",
        "    except:\n",
        "        reviews = None\n",
        "\n",
        "    try:\n",
        "        #full product page URL\n",
        "        url = card.find('a')['href']\n",
        "        product_url = \"https://www.jumia.com.eg\" + url\n",
        "    except:\n",
        "        product_url = None\n",
        "\n",
        "    try:\n",
        "        #image source URL\n",
        "        image = card.find('img')\n",
        "        image_url = image.get('data-src') or image.get('src')\n",
        "    except:\n",
        "        image_url = None\n",
        "\n",
        "    try:\n",
        "        #brand extracted as first word in title\n",
        "        brand = title.split()[0] if title else None\n",
        "    except:\n",
        "        brand = None\n",
        "\n",
        "    return {\n",
        "        'Title': title,\n",
        "        'Price': price,\n",
        "        'Rating': rating,\n",
        "        'Number of Reviews': reviews,\n",
        "        'Product URL': product_url,\n",
        "        'Image URL': image_url,\n",
        "        'Brand': brand\n",
        "    }"
      ],
      "metadata": {
        "id": "8-qzvNpXfbGo"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scrape Multiple Pages Until 100 Products"
      ],
      "metadata": {
        "id": "MSWxoPlPhAL1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time"
      ],
      "metadata": {
        "id": "7_bq7Y-mhFQD"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "page = 1  #start from page 1"
      ],
      "metadata": {
        "id": "CKU9_BVDhHsj"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while len(products) < 100:  #stop once we collect 100 products\n",
        "    print(f\"Scraping page {page}...\")\n",
        "\n",
        "    #Load the webpage using Selenium\n",
        "    driver.get(BASE_URL.format(page=page))\n",
        "\n",
        "    #Wait a few seconds to let the JavaScript content fully load\n",
        "    time.sleep(3)\n",
        "\n",
        "    #use BeautifulSoup to parse the HTML content\n",
        "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
        "\n",
        "    #select all product cards on the current page\n",
        "    cards = soup.find_all('article', class_='prd')\n",
        "\n",
        "    #if no products found, we either reached the end or got blocked\n",
        "    if not cards:\n",
        "        print(\"No products found or blocked.\")\n",
        "        break\n",
        "\n",
        "    #extract data from each product card\n",
        "    for card in cards:\n",
        "        data = extract_data(card)\n",
        "        products.append(data)\n",
        "        if len(products) >= 100:\n",
        "            break\n",
        "\n",
        "    #move to the next page\n",
        "    page += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUWvtrUQdsgo",
        "outputId": "20307442-d946-49fe-ffc1-3cb33c56a8a0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraping page 1...\n",
            "Scraping page 2...\n",
            "Scraping page 3...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save Data to CSV and Close Browser"
      ],
      "metadata": {
        "id": "hJNPTg8AiU5P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "ErbWtQfsiZvq"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#close the browser instance\n",
        "driver.quit()"
      ],
      "metadata": {
        "id": "LSwRszehibxU"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create a DataFrame from the collected product data\n",
        "df = pd.DataFrame(products)"
      ],
      "metadata": {
        "id": "TSijD6SeidsH"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#save the data into a CSV file\n",
        "df.to_csv(\"jumia_laptops.csv\", index=False)\n",
        "print(\"✅ Done — saved 100 laptops to jumia_laptops.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-gzE9aMigQE",
        "outputId": "7f6351d6-7e1e-47c7-f3fa-7350c12e2908"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Done — saved 100 laptops to jumia_laptops.csv\n"
          ]
        }
      ]
    }
  ]
}